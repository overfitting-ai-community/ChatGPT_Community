import streamlit as st
import time
import openai

openai.api_key = st.secrets["api_key"]
st.set_page_config(layout="wide",page_title="Peoply's Feedback AI", page_icon="ğŸ¤–", initial_sidebar_state="auto")
# openai.api_key = "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"

# GPT ëª¨ë¸ ì…‹íŒ…ê°’
name_list = [
    "ì†í¥ë¯¼",
    "ì´ê°•ì¸",
    "ê¹€ë¯¼ì¬"
]

init_fact_gathering = """- SëŒ€ êµìˆ˜ì§„ ë° ì‚°í•™ í˜‘ë ¥ ê³¼ì œë¥¼ ì„ ì •í•˜ê³  ì¶”ì§„í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ë¦¬ë“œí•˜ì˜€ìŒ.
- íŒ€ì˜ ê°€ì¥ ì¤‘ìš”í•œ ê³¼ì œì—ì„œ ë„ì „ì ì¸ PM ì—­í• ì„ ì„±ê³µì ìœ¼ë¡œ ìˆ˜í–‰í•˜ì˜€ìŒ.
- íŠ¹í—ˆ ì¶œì›ì„ í†µí•´ì„œ íŒ€ì˜ ê¸°ìˆ  ë‚´ì¬í™” ëª©ì ì„ ë‹¬ì„±í•˜ì˜€ìŒ.
- ì´í•´ê´€ê³„ìì™€ ì´ìŠˆê°€ ë°œìƒ í•˜ê¸° ì „ì— ì ì‹œì— ì†Œí†µ í•˜ëŠ” ë…¸ë ¥ì´ í•„ìš”í•¨."""

# feedback grade ì…‹íŒ…ê°’
grade_set = {
    'Highly Exceeds' : 5,
    'Exceeds' : 4,
    'Meets' : 3,
    'Marginally Meets' : 2,
    'Does not Meet' : 1
}
grade_list = list(grade_set.keys())

# Temperature ì…‹íŒ…ê°’
temperature_set = {
    'ë‚®ìŒ' : 0.00,
    'ë³´í†µ' : 0.50,
    'ë†’ìŒ' : 1.00
}
temperature_list = list(temperature_set.keys())

# feedback ìƒì„± ìˆ˜ ì…‹íŒ…ê°’
numbs_set = {
    '1' : 1,
    '2' : 2,
    '3' : 3
}
numbs_list = list(numbs_set.keys())

# feedback ê¸€ììˆ˜  ì…‹íŒ…ê°’
length_set = {
    '200' : 200,
    '300' : 300,
    '400' : 400,
    '500' : 500
}
length_list = list(length_set.keys())

# ê¸€ììˆ˜ ì…‹íŒ…ê°’
min_length_of_result = 200
init_length_of_result = 500

# GPT ëª¨ë¸ ì…‹íŒ…ê°’
model_list = [
    "gpt-3.5-turbo",
    "gpt-3.5-turbo-0301"
]

# Session History
if 'gen' not in st.session_state:
    st.session_state.gen = []

class Gen_set():
    name = None
    fact_gathering = None
    grade = None
    temperature = None
    length = None
    model = None
    output = None
    numbs = None

    def set_result(self, input_name, input_fact_gathering, input_grade, input_temperature, input_length, input_model, p_output, input_numbs):
        self.name = input_name
        self.fact_gathering = input_fact_gathering
        self.grade = input_grade
        self.temperature = input_temperature
        self.length = input_length
        self.model = input_model
        self.output = p_output
        self.numbs = input_numbs

def add_set():
    input_name = st.session_state.input_name
    input_fact_gathering = st.session_state.input_fact_gathering
    input_grade_text = st.session_state.input_grade_text
    input_grade = grade_set[input_grade_text]
    input_temperature_text = st.session_state.input_temperature_text
    input_temperature = temperature_set[input_temperature_text]
    input_length_text = st.session_state.input_length_text
    input_length = length_set[input_length_text]
    input_model = st.session_state.input_model
    input_numbs_text = st.session_state.input_numbs_text
    input_numbs = numbs_set[input_numbs_text]

    sys_prompt = f'({st.secrets["system_content"]} + {input_name})'
    usr_prompt = f'({st.secrets.user_content._01} + {input_name} + {st.secrets.user_content._02} + {input_name} + {st.secrets.user_content._03} + {input_name} + {st.secrets.user_content._04} + {input_fact_gathering})'

    gpt_prompt = [{
        "role": "system",
        "content": sys_prompt
    }, {
        "role": "user",
        "content": usr_prompt
    }]

    with st.spinner("Waiting for Feedback AI..."):
        gpt_response = openai.ChatCompletion.create(
            # model used here is ChatGPT
            # You can use all these models for this endpoint:
            # gpt-4, gpt-4-0314, gpt-4-32k, gpt-4-32k-0314,
            # gpt-3.5-turbo, gpt-3.5-turbo-0301
            model=input_model,
            messages=gpt_prompt,
            temperature=input_temperature,
            n=input_numbs,
            max_tokens=3000,
            top_p=1,
            # stream=True
        )

    # t = st.empty()
    # content = ""
    content: list = []
    counter = 0
    # for completions in gpt_response:
    #     counter += 1
    #     if "content" in completions.choices[0].delta:
    #         content += completions.choices[0].delta.get("content")
    #     t.markdown(" %s " % content)
    while input_numbs > counter:
        content.append(gpt_response.choices[counter]['message']['content'])
        counter += 1

    # model = gpt_response.model
    outputs = content

    g = Gen_set()
    g.set_result(input_name, input_fact_gathering, input_grade, input_temperature, input_length, input_model, outputs, input_numbs)

    gen = st.session_state.gen
    gen.append(g)
    st.session_state.gen = gen

def draw_result(input_name, input_fact_gathering, input_grade, input_temperature, input_length, input_model, p_output, input_numbs):
    st.write('---------------')
    st.markdown(f"ì´ë¦„ : **{input_name}**")
    st.write('Fact Gathering')
    st.write(input_fact_gathering)
    st.write('---------------')
    col1, col2 = st.columns(2)
    with col1:
        st.write('- í”¼ë“œë°± ë‹¤ì–‘ì„± ê°’ : ', input_temperature)
        st.write('- ê¸€ììˆ˜ ì œí•œ : ', input_length)
    with col2:
        st.write('- GPT ëª¨ë¸ : ', input_model)
        st.write('- í”¼ë“œë°± ìƒì„± ìˆ˜ : ', input_numbs)
    # st.write('í”¼ë“œë°± ë“±ê¸‰ ê°’ :', input_grade)
    st.write('---------------')
    st.write('- í”¼ë“œë°± ìƒì„± ê²°ê³¼ : ')
    # st.write(p_output)
    for output in p_output:
        # output = f"*** {o} ***"
        # st.markdown(output)
        st.write(output)
        st.write('---------------')
    st.write('---------------')

# st.text("í”¼í‰ê°€ìì— ëŒ€í•œ MBO ë‚´ìš©ì„ ì…ë ¥í•˜ë©´, ChatGPTê°€ MBO í”¼ë“œë°±ì„ ìƒì„±í•©ë‹ˆë‹¤.")

# col1, col2 = st.columns(2)

with st.sidebar:
    # st.subheader("Input")
    # Input Form
    with st.form(key="my_form"):
        st.success('ì•„ë˜ í¼ì„ ì™„ì„±í•´ì„œ í”¼ë“œë°±ì„ ìƒì„±í•˜ì„¸ìš”.', icon="ğŸ“")
        # Name
        st.selectbox(
            "íŒ€ì›ì„ ì„ íƒí•˜ì„¸ìš”.",
            name_list,
            key='input_name'
            )

        # fact_gathering text area
        st.text_area(
            'Fact Gathering:ì‹¤ì , íŒ€ ê³µí—Œ, ê°œì„ , ì¹­ì°¬í•  ì ì„ ê°„ëµíˆ ì•Œë ¤ ì£¼ì„¸ìš”.',
            init_fact_gathering,
            height=170,
            key='input_fact_gathering'
            )

        # feedback grade
        st.selectbox(
            'í”¼ë“œë°± ë“±ê¸‰ì„ ì„ íƒí•˜ì„¸ìš”.',
            grade_list,
            index=2,
            disabled=True,
            key='input_grade_text'
            )

        # GPT model
        st.selectbox(
            "GPT ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”.",
            model_list,
            key='input_model'
        )

        # Temperature
        st.select_slider(
            'í”¼ë“œë°±ì˜ ë‹¤ì–‘ì„±ì„ ì„ íƒí•˜ì„¸ìš”.',
            options=temperature_list,
            key='input_temperature_text'
            )

        # length of result
        st.selectbox(
            "ìƒì„±í•  í”¼ë“œë°± ìˆ˜ë¥¼ ì„ íƒ í•˜ì„¸ìš”.",
            numbs_list,
            key='input_numbs_text'
        )

        # length of result
        st.selectbox(
            'ê¸€ììˆ˜ë¥¼ ì œí•œí•´ ì£¼ì„¸ìš”.',
            length_list,
            key='input_length_text'
            )

        st.form_submit_button("Generate", on_click=add_set)

st.image('https://raw.githubusercontent.com/overfitting-ai-community/ChatGPT_Gen_Comment/f6e0722f128f8bb5ee85f29dd52fcb8a6d8784eb/peoply.png', width=130)
st.info('**ğŸ¤– Feedback AIê°€ ìƒì„±í•˜ëŠ” ë‚´ìš©ì„ ì•„ë˜ì—ì„œ í™•ì¸ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**')

# Result
if(len(st.session_state.gen) > 0):
    # for i in range(len(st.session_state.gen)):
    #     set = st.session_state.gen[i]
    #     draw_result(set.name, set.fact_gathering, set.grade, set.temperature, set.length, set.model, set.output, set.numbs)
    for idx, set in reversed(list(enumerate(st.session_state.gen))):
        draw_result(set.name, set.fact_gathering, set.grade, set.temperature, set.length, set.model, set.output,
                    set.numbs)
